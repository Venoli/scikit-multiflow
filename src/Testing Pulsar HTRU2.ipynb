{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: scikit-multiflow in /Users/venoligamage/Documents/FYP/Implementation/Asips/scikit-multiflow/src (0.6.dev0)\n",
      "Requirement already satisfied, skipping upgrade: sortedcontainers>=1.5.7 in /Users/venoligamage/opt/anaconda3/lib/python3.8/site-packages (from scikit-multiflow) (2.2.2)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.14.0 in /Users/venoligamage/opt/anaconda3/lib/python3.8/site-packages (from scikit-multiflow) (1.20.2)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=1.0.0 in /Users/venoligamage/opt/anaconda3/lib/python3.8/site-packages (from scikit-multiflow) (1.5.2)\n",
      "Requirement already satisfied, skipping upgrade: matplotlib>=2.0.0 in /Users/venoligamage/opt/anaconda3/lib/python3.8/site-packages (from scikit-multiflow) (3.3.2)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn>=0.20 in /Users/venoligamage/opt/anaconda3/lib/python3.8/site-packages (from scikit-multiflow) (0.23.2)\n",
      "Requirement already satisfied, skipping upgrade: pandas>=0.25.3 in /Users/venoligamage/opt/anaconda3/lib/python3.8/site-packages (from scikit-multiflow) (1.1.3)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.1 in /Users/venoligamage/opt/anaconda3/lib/python3.8/site-packages (from matplotlib>=2.0.0->scikit-multiflow) (2.8.1)\n",
      "Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /Users/venoligamage/opt/anaconda3/lib/python3.8/site-packages (from matplotlib>=2.0.0->scikit-multiflow) (1.3.0)\n",
      "Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /Users/venoligamage/opt/anaconda3/lib/python3.8/site-packages (from matplotlib>=2.0.0->scikit-multiflow) (2.4.7)\n",
      "Requirement already satisfied, skipping upgrade: cycler>=0.10 in /Users/venoligamage/opt/anaconda3/lib/python3.8/site-packages (from matplotlib>=2.0.0->scikit-multiflow) (0.10.0)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2020.06.20 in /Users/venoligamage/opt/anaconda3/lib/python3.8/site-packages (from matplotlib>=2.0.0->scikit-multiflow) (2020.6.20)\n",
      "Requirement already satisfied, skipping upgrade: pillow>=6.2.0 in /Users/venoligamage/opt/anaconda3/lib/python3.8/site-packages (from matplotlib>=2.0.0->scikit-multiflow) (8.0.1)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /Users/venoligamage/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.20->scikit-multiflow) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /Users/venoligamage/opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.20->scikit-multiflow) (0.17.0)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /Users/venoligamage/opt/anaconda3/lib/python3.8/site-packages (from pandas>=0.25.3->scikit-multiflow) (2020.1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /Users/venoligamage/opt/anaconda3/lib/python3.8/site-packages (from python-dateutil>=2.1->matplotlib>=2.0.0->scikit-multiflow) (1.15.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U scikit-multiflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('pulsar_data_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "#imputer = SimpleImputer(missing_values = \"NaN\", strategy = \"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.21156250e+02  4.83729711e+01  3.75484665e-01 ...  7.44987415e+00\n",
      "   6.51592977e+01  0.00000000e+00]\n",
      " [ 7.69687500e+01  3.61755566e+01  7.12897860e-01 ...  9.41465226e+00\n",
      "   1.02722975e+02  0.00000000e+00]\n",
      " [ 1.30585938e+02  5.32295335e+01  1.33408289e-01 ...  8.50836378e+00\n",
      "   7.40313242e+01  0.00000000e+00]\n",
      " ...\n",
      " [ 1.16031250e+02  4.32138464e+01  6.63455691e-01 ...  1.70552145e+01\n",
      "   3.12204325e+02  0.00000000e+00]\n",
      " [ 1.35664062e+02  4.99337494e+01 -8.99403060e-02 ...  7.39839490e+00\n",
      "   6.23340175e+01  0.00000000e+00]\n",
      " [ 1.20726562e+02  5.04722564e+01  3.46178079e-01 ...  1.76622219e+01\n",
      "   3.29548016e+02  0.00000000e+00]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\sklearn\\impute\\_base.py:356: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  row_mask = np.logical_not(row_mask).astype(np.bool)\n",
      "C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\sklearn\\impute\\_base.py:356: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  row_mask = np.logical_not(row_mask).astype(np.bool)\n",
      "C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\sklearn\\impute\\_base.py:356: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  row_mask = np.logical_not(row_mask).astype(np.bool)\n",
      "C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\sklearn\\impute\\_base.py:356: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  row_mask = np.logical_not(row_mask).astype(np.bool)\n",
      "C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\sklearn\\impute\\_base.py:356: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  row_mask = np.logical_not(row_mask).astype(np.bool)\n",
      "C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\sklearn\\impute\\_base.py:356: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  row_mask = np.logical_not(row_mask).astype(np.bool)\n",
      "C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\sklearn\\impute\\_base.py:356: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  row_mask = np.logical_not(row_mask).astype(np.bool)\n",
      "C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\sklearn\\impute\\_base.py:356: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  row_mask = np.logical_not(row_mask).astype(np.bool)\n",
      "C:\\Users\\dell\\Anaconda3\\lib\\site-packages\\sklearn\\impute\\_base.py:356: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  row_mask = np.logical_not(row_mask).astype(np.bool)\n"
     ]
    }
   ],
   "source": [
    "imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "print(imputer.fit_transform(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:\n",
      "['Mean of the integrated profile', 'Standard deviation of the integrated profile', 'Excess kurtosis of the integrated profile', 'Skewness of the integrated profile', 'Mean of the DM-SNR curve', 'Standard deviation of the DM-SNR curve', 'Excess kurtosis of the DM-SNR curve', 'Skewness of the DM-SNR curve']\n",
      "Number of Targets: 1\n",
      "Name: ['target_class']\n",
      "Target class values: [0, 1]\n"
     ]
    }
   ],
   "source": [
    "#Alrady tested. fast,not incrimently learn, not solve imbalance problem\n",
    "from skmultiflow.data import FileStream\n",
    "\n",
    "# 1. Create a stream\n",
    "\n",
    "stream = FileStream('pulsar_data_train.csv')\n",
    "#(./name)\n",
    "print(\"Features:\")\n",
    "print(stream.feature_names)\n",
    "print(\"Number of Targets: \" + str(stream.n_targets)+\"\\nName: \"+str(stream.target_names))\n",
    "print(\"Target class values: \" + str(stream.target_values))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "def evaluationMesures(y_true_all, y_pred_all): \n",
    "  tn, fp, fn, tp = confusion_matrix(y_true_all,y_pred_all).ravel()\n",
    "  recall = recall_score(y_true_all, y_pred_all)\n",
    "  precision = precision_score(y_true_all, y_pred_all)\n",
    "  accuracy = accuracy_score(y_true_all, y_pred_all)\n",
    "  f1 = f1_score(y_true_all, y_pred_all)\n",
    "  specificity = tn/(tn + fp)\n",
    "  G_mean = np.sqrt((precision * specificity))\n",
    "\n",
    "  print('Accuracy: {0} \\nRecall: {1} \\nPrecision: {2} \\nF1 Score: {3} \\nSpecificity(TNR): {4} \\nG-Mean: {5}'\n",
    "      .format(accuracy,recall,precision,f1,specificity,G_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GH-EFDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info: \n",
      "<bound method BaseSKMObject.get_info of ExtremelyFastDecisionTreeClassifier(binary_split=False, grace_period=200,\n",
      "                                    leaf_prediction='nba',\n",
      "                                    max_byte_size=33554432,\n",
      "                                    memory_estimate_period=1000000,\n",
      "                                    min_samples_reevaluate=20, nb_threshold=0,\n",
      "                                    nominal_attributes=None,\n",
      "                                    split_confidence=1e-07,\n",
      "                                    split_criterion='gaussian_hellinger',\n",
      "                                    stop_mem_management=False,\n",
      "                                    tie_threshold=0.05)>\n",
      "9273 samples analyzed.\n",
      "0:01:51.825267 Time difference\n",
      "info: \n",
      "<bound method BaseSKMObject.get_info of ExtremelyFastDecisionTreeClassifier(binary_split=False, grace_period=200,\n",
      "                                    leaf_prediction='nba',\n",
      "                                    max_byte_size=33554432,\n",
      "                                    memory_estimate_period=1000000,\n",
      "                                    min_samples_reevaluate=20, nb_threshold=0,\n",
      "                                    nominal_attributes=None,\n",
      "                                    split_confidence=1e-07,\n",
      "                                    split_criterion='gaussian_hellinger',\n",
      "                                    stop_mem_management=False,\n",
      "                                    tie_threshold=0.05)>\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from skmultiflow.trees import ExtremelyFastDecisionTreeClassifier\n",
    "#fast(not much as ht),incremantly learn, not slove imbalance problem \n",
    "import numpy as np\n",
    "#from skmultiflow.trees.split_criterion import GiniSplitCriterion\n",
    "from skmultiflow.data import FileStream\n",
    "stream = FileStream('pulsar_data_train.csv')\n",
    "\n",
    "efdtgh = ExtremelyFastDecisionTreeClassifier(split_criterion='gaussian_hellinger')\n",
    "\n",
    "\n",
    "print(\"info: \")\n",
    "print(efdtgh.get_info)\n",
    "# Setup variables to control loop and track performance\n",
    "n_samples = 0\n",
    "max_samples = 20000\n",
    "y_true_all = []\n",
    "y_pred_all = []\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "# Train the estimator with the samples provided by the data stream\n",
    "while n_samples < max_samples and stream.has_more_samples():\n",
    "    X, y = stream.next_sample()\n",
    "    y_pred = efdtgh.predict(X)\n",
    "    y_true_all.append(y[0])\n",
    "    y_pred_all.append(y_pred[0])\n",
    "    efdtgh.partial_fit(X, y)\n",
    "    n_samples += 1\n",
    "    \n",
    "    \n",
    "end_time = datetime.datetime.now()\n",
    "time_difference = end_time - start_time\n",
    "print('{} samples analyzed.'.format(n_samples))\n",
    "print('{} Time difference'.format(time_difference))\n",
    "print(\"info: \")\n",
    "print(efdtgh.get_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9674323304216542 \n",
      "Recall: 0.7505882352941177 \n",
      "Precision: 0.8763736263736264 \n",
      "F1 Score: 0.808618504435995 \n",
      "Specificity(TNR): 0.9893149709129764 \n",
      "G-Mean: 0.9311334752250742\n"
     ]
    }
   ],
   "source": [
    "evaluationMesures(y_true_all,y_pred_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GH-VFDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info: \n",
      "<bound method BaseSKMObject.get_info of HoeffdingTreeClassifier(binary_split=False, grace_period=200,\n",
      "                        leaf_prediction='nba', max_byte_size=33554432,\n",
      "                        memory_estimate_period=1000000, nb_threshold=0,\n",
      "                        no_preprune=False, nominal_attributes=None,\n",
      "                        remove_poor_atts=False, split_confidence=1e-07,\n",
      "                        split_criterion='gaussian_hellinger',\n",
      "                        stop_mem_management=False, tie_threshold=0.05)>\n",
      "9273 samples analyzed.\n",
      "0:00:01.019455 Time difference\n",
      "info: \n",
      "<bound method BaseSKMObject.get_info of HoeffdingTreeClassifier(binary_split=False, grace_period=200,\n",
      "                        leaf_prediction='nba', max_byte_size=33554432,\n",
      "                        memory_estimate_period=1000000, nb_threshold=0,\n",
      "                        no_preprune=False, nominal_attributes=None,\n",
      "                        remove_poor_atts=False, split_confidence=1e-07,\n",
      "                        split_criterion='gaussian_hellinger',\n",
      "                        stop_mem_management=False, tie_threshold=0.05)>\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from skmultiflow.trees import HoeffdingTreeClassifier\n",
    "#fast(not much as ht),incremantly learn, not slove imbalance problem \n",
    "import numpy as np\n",
    "#from skmultiflow.trees.split_criterion import GiniSplitCriterion\n",
    "from skmultiflow.data import FileStream\n",
    "stream = FileStream('pulsar_data_train.csv')\n",
    "\n",
    "model = HoeffdingTreeClassifier(split_criterion='gaussian_hellinger')\n",
    "\n",
    "\n",
    "print(\"info: \")\n",
    "print(model.get_info)\n",
    "# Setup variables to control loop and track performance\n",
    "n_samples = 0\n",
    "max_samples = 20000\n",
    "y_true_all = []\n",
    "y_pred_all = []\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "# Train the estimator with the samples provided by the data stream\n",
    "while n_samples < max_samples and stream.has_more_samples():\n",
    "    X, y = stream.next_sample()\n",
    "    y_pred = model.predict(X)\n",
    "    y_true_all.append(y[0])\n",
    "    y_pred_all.append(y_pred[0])\n",
    "    model.partial_fit(X, y)\n",
    "    n_samples += 1\n",
    "    \n",
    "    \n",
    "end_time = datetime.datetime.now()\n",
    "time_difference = end_time - start_time\n",
    "print('{} samples analyzed.'.format(n_samples))\n",
    "print('{} Time difference'.format(time_difference))\n",
    "print(\"info: \")\n",
    "print(model.get_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9583737733203925 \n",
      "Recall: 0.7741176470588236 \n",
      "Precision: 0.7723004694835681 \n",
      "F1 Score: 0.7732079905992949 \n",
      "Specificity(TNR): 0.9769678261901935 \n",
      "G-Mean: 0.8686269111862857\n"
     ]
    }
   ],
   "source": [
    "evaluationMesures(y_true_all,y_pred_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OnlineSMOTEBaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info: \n",
      "<bound method BaseSKMObject.get_info of OnlineSMOTEBaggingClassifier(base_estimator=KNNADWINClassifier(leaf_size=30,\n",
      "                                                               max_window_size=1000,\n",
      "                                                               metric='euclidean',\n",
      "                                                               n_neighbors=5),\n",
      "                             drift_detection=True, n_estimators=10,\n",
      "                             random_state=None, sampling_rate=1)>\n",
      "9273 samples analyzed.\n",
      "0:01:50.791627 Time difference\n",
      "info: \n",
      "<bound method BaseSKMObject.get_info of OnlineSMOTEBaggingClassifier(base_estimator=KNNADWINClassifier(leaf_size=30,\n",
      "                                                               max_window_size=1000,\n",
      "                                                               metric='euclidean',\n",
      "                                                               n_neighbors=5),\n",
      "                             drift_detection=True, n_estimators=10,\n",
      "                             random_state=None, sampling_rate=1)>\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from skmultiflow.meta import OnlineSMOTEBaggingClassifier\n",
    "#fast(not much as ht),incremantly learn, not slove imbalance problem \n",
    "import numpy as np\n",
    "#from skmultiflow.trees.split_criterion import GiniSplitCriterion\n",
    "from skmultiflow.data import FileStream\n",
    "stream = FileStream('pulsar_data_train.csv')\n",
    "\n",
    "model = OnlineSMOTEBaggingClassifier()\n",
    "\n",
    "\n",
    "print(\"info: \")\n",
    "print(model.get_info)\n",
    "# Setup variables to control loop and track performance\n",
    "n_samples = 0\n",
    "max_samples = 20000\n",
    "y_true_all = []\n",
    "y_pred_all = []\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "# Train the estimator with the samples provided by the data stream\n",
    "while n_samples < max_samples and stream.has_more_samples():\n",
    "    X, y = stream.next_sample()\n",
    "    y_pred = model.predict(X)\n",
    "    y_true_all.append(y[0])\n",
    "    y_pred_all.append(y_pred[0])\n",
    "    model.partial_fit(X, y,np.array([0,1]))\n",
    "    n_samples += 1\n",
    "    \n",
    "    \n",
    "end_time = datetime.datetime.now()\n",
    "time_difference = end_time - start_time\n",
    "print('{} samples analyzed.'.format(n_samples))\n",
    "print('{} Time difference'.format(time_difference))\n",
    "print(\"info: \")\n",
    "print(model.get_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9681872101800928 \n",
      "Recall: 0.7035294117647058 \n",
      "Precision: 0.9329173166926678 \n",
      "F1 Score: 0.8021462105969148 \n",
      "Specificity(TNR): 0.9948949305473109 \n",
      "G-Mean: 0.9634078622252028\n"
     ]
    }
   ],
   "source": [
    "evaluationMesures(y_true_all,y_pred_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OnlineUnderOverBaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info: \n",
      "<bound method BaseSKMObject.get_info of OnlineUnderOverBaggingClassifier(base_estimator=KNNADWINClassifier(leaf_size=30,\n",
      "                                                                   max_window_size=1000,\n",
      "                                                                   metric='euclidean',\n",
      "                                                                   n_neighbors=5),\n",
      "                                 drift_detection=True, n_estimators=10,\n",
      "                                 random_state=None, sampling_rate=2)>\n",
      "9000 samples analyzed.\n",
      "0:01:20.830538 Time difference\n",
      "info: \n",
      "<bound method BaseSKMObject.get_info of OnlineUnderOverBaggingClassifier(base_estimator=KNNADWINClassifier(leaf_size=30,\n",
      "                                                                   max_window_size=1000,\n",
      "                                                                   metric='euclidean',\n",
      "                                                                   n_neighbors=5),\n",
      "                                 drift_detection=True, n_estimators=10,\n",
      "                                 random_state=None, sampling_rate=2)>\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from skmultiflow.meta import OnlineUnderOverBaggingClassifier\n",
    "import numpy as np\n",
    "from skmultiflow.data import FileStream\n",
    "stream = FileStream('pulsar_data_train.csv')\n",
    "\n",
    "model = OnlineUnderOverBaggingClassifier()\n",
    "\n",
    "\n",
    "print(\"info: \")\n",
    "print(model.get_info)\n",
    "# Setup variables to control loop and track performance\n",
    "n_samples = 0\n",
    "max_samples = 9000\n",
    "y_true_all = []\n",
    "y_pred_all = []\n",
    "wait_samples = 300\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "# Train the estimator with the samples provided by the data stream\n",
    "while n_samples < max_samples and stream.has_more_samples():\n",
    "    X, y = stream.next_sample()\n",
    "    y_pred = model.predict(X)\n",
    "    if (n_samples > wait_samples):\n",
    "        y_true_all.append(y[0])\n",
    "        y_pred_all.append(y_pred[0])\n",
    "    model.partial_fit(X, y,np.array([0,1]))\n",
    "    n_samples += 1\n",
    "    \n",
    "    \n",
    "end_time = datetime.datetime.now()\n",
    "time_difference = end_time - start_time\n",
    "print('{} samples analyzed.'.format(n_samples))\n",
    "print('{} Time difference'.format(time_difference))\n",
    "print(\"info: \")\n",
    "print(model.get_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9692656098350049 \n",
      "Recall: 0.7941176470588235 \n",
      "Precision: 0.8598726114649682 \n",
      "F1 Score: 0.8256880733944956 \n",
      "Specificity(TNR): 0.9869405200047489 \n",
      "G-Mean: 0.9212182815690736\n"
     ]
    }
   ],
   "source": [
    "evaluationMesures(y_true_all,y_pred_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9701115070697781 \n",
      "Recall: 0.7934508816120907 \n",
      "Precision: 0.8677685950413223 \n",
      "F1 Score: 0.8289473684210527 \n",
      "Specificity(TNR): 0.9878557874762809 \n",
      "G-Mean: 0.9258672846589469\n"
     ]
    }
   ],
   "source": [
    "evaluationMesures(y_true_all,y_pred_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
